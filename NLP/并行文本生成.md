---
title: 并行文本生成
mathjax: true
date: 2021-10-22 14:27:50
tags:
- NLP
- 文本生成
categories: 
- NLP
---

### 什么是并行文本生成任务

#### 文本生成的定义

一般地认为：1. 文本到文本的生成；2：数据到文本的生成；3：图像到文本的生成。即为文本生成任务。

#### 文本生成任务

文本生成任务包含的任务（包含但不仅限于）：

- 摘要生成
- 机器翻译
- 标题生成
- OCR
- …

<!--more-->

#### 框架

目前深度学习时代使用比较广泛的有seq2seq的编码器-解码器框架

#### 文本生成形式

- 自左向右的文本生成 - 自回归

  - 自回归模型采用自左向右的方式按照顺序逐词生成文本

    - Transformer
    - RNN

    $$p(Y|X;\theta)=\displaystyle \prod^{T}_{t=0}{p(y_t|y<t，X；\theta})$$

    <img src="并行文本生成/截屏2021-10-22 下午3.05.54.png" alt="自回归" style="zoom:25%;" />

- 并行文本生成 - 自编码

  - 并行输出句子中的所有文本

    $$p(Y|X;\theta)=\displaystyle \prod^{T}_{t=0}{p(y_t|X；\theta})$$

    <img src="并行文本生成/截屏2021-10-22 下午3.06.30.png" alt="并行" style="zoom:25%;" />

### 并行文本生成的优势

#### 性能优势

- GPU可以用时并行执行多个计算
- 并行解码的速度比自左向右解码速度更快

#### 潜在优势

- 自左向右的解码只使用了当前位置左边的信息进行局部预测
- 并行解码可以同时利用左右两边的上下文信息

#### 孰优孰劣

目前自回归解码应该是占据主导地位，但是同时期的图像并行生成与自回归生成中，并行生成要优于自回归生成

### 并行文本生成的发展研究

#### 基础的并行生成模型

第一次是在2018年 [non-autoregressive neural machine translation](https://arxiv.org/abs/1711.02281)提出并行文本生成模型

- 编码器和自回归模型保持相同
- 复制编码器的表示作为编码器的输入
- 在解码之前先预测输出长度

#### 模型结构对比

<center class="half">    <img src="并行文本生成/截屏2021-10-22 下午5.44.22.png" alt="自回归" width="300"/>    <img src="并行文本生成/截屏2021-10-22 下午5.47.47.png" alt="并行" width="300"/> </center>

#### 关于并行生成模型的输出长度

1. 在解码之前先预测长度 - 可以预测多种长度下的输出结果

很多树 -> a lot of trees

很多树 -> many trees

2. 预先设定最大长度 - 需要去除解码结果中多余的部分

很多树 -> many many _ trees -> many trees

#### 区别

|            | 自回归模型          | 并行生成模型             |
| ---------- | ------------------- | ------------------------ |
| 解码器输入 | 之前部分的输出序列  | 来自编码器               |
| 上下文信息 | 单向                | 双向                     |
| 输出长度   | 输出`<EOS>`作为终止 | 先预测长度或指定最大长度 |

### 存在的问题

- 同一个输入可以有多个不通的输出

很多树->a lot of trees

很多树->a great many trees

- 并行生成会出现用词不一致的问题

很多树->a great of trees

很多树->a many of trees

很多树->a lot of trees

#### 解决方案

- 引入隐变量
  - 预测额外的隐变量𝑍来帮助模型建模输出𝑦之间的关系

    <img src="并行文本生成/截屏2021-10-22 下午6.18.47.png" alt="引入隐变量" style="zoom: 25%;" />

  - 隐变量的设计存在困难

    - 简单的隐变量，性能较弱
    - 复杂的隐变量，难以预测并且预测速度慢

- 迭代式解码

  - 使用多轮并行解码修改输出

    <img src="并行文本生成/截屏2021-10-22 下午6.20.46.png" alt="迭代式解码" style="zoom:25%;" />

  - 多轮解码减慢了生成速度

  - 只解码一次时的生成质量差

- 单词并行文本生成
  - 建模词之间的依赖关系

### 为并行生成建模词之间的依赖关系

#### 词之间的依赖关系

- 并行文本生成模型缺乏一种学习依赖关系的有效方式
- 语句中的词通过依赖关系形成正确的语法结构和搭配

#### 并行生成模型的常规训练方式

- 最大似然估计 - 缺少目标词之间依赖关系的显式建模

$$L_{\theta}=-logp(Y|X;\theta)  \rightarrow   p(Y|X;\theta)=\displaystyle \prod^{T}_{t=0}{p(y_t|X；\theta})$$

<img src="并行文本生成/截屏2021-10-22 下午6.30.05.png" alt="并行文本生成" style="zoom:25%;" />

#### 学习词之间的依赖关系

- 自回归模型 - 根据前面位置的目标词输入预测下一个词（从左往右）

<img src="并行文本生成/截屏2021-10-22 下午6.59.50.png" alt="自回归模型结构" style="zoom:25%;" />

- 迭代式并行生成模型 - 根据部分目标词输入预测被随机掩盖的词 - 需要多轮解码才能达到比较好的效果

<img src="并行文本生成/截屏2021-10-22 下午7.01.11.png" alt="生成式模型结构" style="zoom:25%;" />

- 单词并行生成建模词之间的依赖关系存在的问题
  - 学习词之间的依赖关系需要目标词作为输入
  - 单次并行生成在输出之前得不到任何目标词
- 单词并行生成建模词之间的依赖关系解决方案
  - GlancingLanguageModel (GLM)：一种渐进式的训练方法

### GLM（GlancingLanguageModel）

使用一种动态自适应的采样策略来引导渐进式的训练 - 从学习并行生成片段开始逐渐学习整个句子的并行生成

<img src="并行文本生成/截屏2021-10-22 下午8.41.10.png" alt="模型结构" style="zoom:25%;" />

Qian L, Zhou H, Bao Y, et al. Glancing Transformer for Non-autoregressive Neural Machine Translation. ACL-IJCNLP2021.

<img src="并行文本生成/截屏2021-10-22 下午8.43.29.png" alt="解码过程" style="zoom:25%;" />

在训练中进行两次解码（在生成中只进行一次解码）

#### 解码过程

1. 计算第一次解码结果和目标语句的距离。

2. 计算目标词和采样数量 $N=d(\hat{y}, y) * f_{ratio}$，并将采样词替换到解码器输入中。

   d：汉明距离

   f：采样率，这里采用的0.5

3. 第二次解码通过替换过的解码器输入预测剩余的目标词的并行生成。

<img src="并行文本生成/截屏2021-10-26 下午12_mosaic.png" alt="训练策略" style="zoom:25%;" />

在训练中，目标词的采样率逐渐减少，模型随之学习更长片段的并行文本生成。

<img src="并行文本生成/截屏2021-10-26 下午12.25.03.png" alt="训练策略" style="zoom:25%;" />

机器翻译效果

<img src="并行文本生成/截屏2021-10-26 下午1.07.30.png" alt="训练策略对比" style="zoom:25%;" />

模型结构相同的情况下，使用GLM训练策略能够提升翻译效果。

<img src="并行文本生成/截屏2021-10-26 下午1.07.57.png" alt="模型对比" style="zoom:25%;" />

CTC：提前设定一个翻译结果长度

NPD：预测多个长度，最后做一次reranking，选取效果最好的结果

最终效果和transformer相当，解码速度是transformer的8~15倍

自适应采样策略的有效性：

![自适应采样策略对比](并行文本生成/截屏2021-10-26 下午1_mosaic.png)

如何选择作为输入的目标词：

<img src="并行文本生成/截屏2021-10-26 下午1.13.55.png" alt="如何选择作为输入的目标词" style="zoom:25%;" />

$P_{ref}:$采样比较容易预测的词

$1- P_{ref}:$采样比较难预测的词

